---
title: TiDB Cloud Performance Highlights for TiDB v8.5.0
summary: TiDB バージョン v8.5.0 では、 TiDB Cloud Dedicated クラスターのパフォーマンスが向上しました。
---

# TiDB v8.5.0 のTiDB Cloudパフォーマンスのハイライト {#tidb-cloud-performance-highlights-for-tidb-v8-5-0}

[TiDB v8.5.0](https://docs.pingcap.com/tidb/v8.5/release-8.5.0)重要な長期サポート (LTS) リリースであり、パフォーマンス、スケーラビリティ、運用効率が大幅に向上しています。

このドキュメントでは、次の領域における v8.5.0 のパフォーマンス改善について概説します。

-   全般的なパフォーマンス
-   過剰な MVCC バージョンによるホットスポット読み取り
-   IOレイテンシージッター
-   バッチ処理
-   TiKVスケーリングパフォーマンス

## 全般的なパフォーマンス {#general-performance}

v8.5.0 では、デフォルトのリージョンサイズが 96 MiB から 256 MiB に増加し、その他のいくつかの改善も行われたため、パフォーマンスが大幅に向上しました。

-   `oltp_insert`パフォーマンスが 27% 向上します。
-   `Analyze`パフォーマンスは約 45% の大幅な向上を示します。

## 過剰な MVCC バージョンによるホットスポット読み取り {#hotspot-reads-with-excessive-mvcc-versions}

### チャレンジ {#challenge}

一部のユーザー シナリオでは、次のような課題が発生する可能性があります。

-   頻繁なバージョン更新: 一部のワークロードでは、データが非常に頻繁に更新され、読み取られます。
-   履歴バージョンの長期保存: 特定の時点へのフラッシュバックのサポートなどのビジネス要件を満たすために、ユーザーは GC (ガベージ コレクション) 時間を過度に長く設定する場合があります (24 時間など)。その結果、マルチバージョン同時実行制御 (MVCC) バージョンが過剰に蓄積され、クエリの効率が大幅に低下します。

MVCC バージョンが蓄積されると、要求されたデータと処理されたデータの間に大きなギャップが生じ、読み取りパフォーマンスが低下します。

### 解決 {#solution}

この問題に対処するために、TiKV では[インメモリエンジン (IME)](https://docs.pingcap.com/tidb/stable/tikv-in-memory-engine)導入しています。最新バージョンをメモリにキャッシュすることで、TiKV は履歴バージョンが読み取りパフォーマンスに与える影響を軽減し、クエリの効率を大幅に向上させます。

### テスト環境 {#test-environment}

-   クラスタトポロジ: TiDB (16 vCPU、32 GiB) * 1 + TiKV (16 vCPU、32 GiB) * 6

-   クラスタ構成:

        tikv_configs:
        [in-memory-engine]
        enable = true

-   データセット: 頻繁に更新されるデータを含む、約 340 のリージョンを持つ 24 GiB のstorageサイズ

-   ワークロード: スキャンを必要とする行には、頻繁な更新によって導入された多数の MVCC バージョンが含まれています。

### テスト結果 {#test-results}

クエリのレイテンシーは 50% 減少し、スループットは 100% 増加します。

| コンフィグレーション | 期間（秒） | スレッド | TPPSについて | 品質保証   | 平均レイテンシー（ミリ秒） | P95レイテンシー(ミリ秒) |
| ---------- | ----- | ---- | -------- | ------ | ------------- | -------------- |
| IMEを無効にする  | 3600  | 10   | 123.8    | 1498.3 | 80.76         | 207.82         |
| IMEを有効にする  | 3600  | 10   | 238.2    | 2881.5 | 41.99         | 78.60          |

## IOレイテンシージッター {#io-latency-jitter}

### チャレンジ {#challenge}

クラウド環境では、クラウド ディスク上の一時的または持続的な IOレイテンシーの変動が一般的な課題です。これらの変動により、リクエストのレイテンシーが増加し、タイムアウト、エラー、通常の業務の中断が発生し、最終的にサービス品質が低下します。

### 解決 {#solution}

TiDB v8.5.0 では、クラウド ディスク IO ジッターによるパフォーマンスへの影響を軽減するための複数の機能強化が導入されています。

-   **Leader書き込み最適化**: リーダーがコミットされたRaftログを適用できるようにし、リーダー ピアの書き込みレイテンシーに対する IO ジッターの影響を軽減します。
-   **強化された低速ノード検出**: 低速ノード検出アルゴリズムを改良し、デフォルトで低速スコア検出を有効にします。これにより、低速ノードが特定されると、エビクトリーダー スケジューラがトリガーされ、パフォーマンスが回復されます。
-   **統合ヘルス コントローラー**: TiKV に統合ヘルス コントローラーを追加し、KV クライアントにフィードバック メカニズムを追加します。KV クライアントは、TiKV ノードのヘルスとパフォーマンスに基づいて、エラー処理とレプリカの選択を最適化します。
-   **改良されたレプリカ セレクター**: KV クライアントにレプリカ セレクター V2 が導入され、不要な再試行やバックオフ操作を排除する改良された状態遷移が実現しました。
-   **追加の修正と改善**: TiKV のストア ループでの不要な IO 操作を回避しながら、リージョン キャッシュや KV クライアント ヘルス チェッカーなどの重要なコンポーネントの機能強化が含まれています。

### テスト環境 {#test-environment}

-   クラスタトポロジ: TiDB (32 vCPU、64 GiB) * 3 + TiKV (32 vCPU、64 GiB) * 6
-   ワークロード: 読み取り/書き込み比率 2:1、シミュレートされたクラウド ディスク IO 遅延または 1 つの TiKV ノードでのハング

### テスト結果 {#test-results}

IOレイテンシージッターのフェイルオーバー時間は 30% 短縮され、P99/999レイテンシーは 70% 以上削減されます。

-   IOレイテンシージッターの改善なしのテスト結果

    | 作業負荷                    | フェイルオーバー時間          | QPS 低下率 | フェイルオーバー時の最大レイテンシー（P999） | フェイルオーバー時の最大レイテンシー（P99） |
    | ----------------------- | ------------------- | ------- | ------------------------ | ----------------------- |
    | 1秒のIO遅延は10分間続きます        | 4分                  | 99%     | 1分                       | 56秒                     |
    | 500 ミリ秒の IO 遅延が 10 分間続く | 4分                  | 99%     | 54秒                      | 7.8秒                    |
    | 100 ミリ秒の IO 遅延が 10 分間続く | フェイルオーバーが達成されませんでした | 99%     | 32秒                      | 26秒                     |
    | 50 ミリ秒の IO 遅延が 10 分間続く  | フェイルオーバーが達成されませんでした | 97%     | 13.2秒                    | 6.7秒                    |
    | 10 ミリ秒の IO 遅延が 10 分間続く  | フェイルオーバーが達成されませんでした | 94%     | 3秒                       | 1.45秒                   |
    | 5 ミリ秒の IO 遅延が 10 分間続く   | フェイルオーバーが達成されませんでした | 81%     | 462 ミリ秒                  | 246ミリ秒                  |
    | 2 ミリ秒の IO 遅延が 10 分間続く   | フェイルオーバーが達成されませんでした | 38%     | 232ミリ秒                   | 22.9ミリ秒                 |

-   IOレイテンシージッターの改善によるテスト結果

    | 作業負荷                    | フェイルオーバー時間 | QPS ドロップ率 | フェイルオーバー時の最大レイテンシー（P999） | フェイルオーバー時の最大レイテンシー（P99） |
    | ----------------------- | ---------- | --------- | ------------------------ | ----------------------- |
    | 1秒のIO遅延は10分間続きます        | 3分         | 93%       | 4.66秒                    | 929ミリ秒                  |
    | 500 ミリ秒の IO 遅延が 10 分間続く | 2分         | 92%       | 7.22秒                    | 894ミリ秒                  |
    | 100 ミリ秒の IO 遅延が 10 分間続く | 3分         | 80%       | 7.53秒                    | 1.7秒                    |
    | 50 ミリ秒の IO 遅延が 10 分間続く  | 3分         | 53%       | 1.36秒                    | 238ミリ秒                  |
    | 10 ミリ秒の IO 遅延が 10 分間続く  | 3分         | 18%       | 69ミリ秒                    | 25ミリ秒                   |
    | 5 ミリ秒の IO 遅延が 10 分間続く   | 2分         | 29%       | 37.9ミリ秒                  | 10ミリ秒                   |
    | 2 ミリ秒の IO 遅延が 10 分間続く   | ほとんど効果なし   | 1%        | 14ミリ秒                    | 7.9ミリ秒                  |

## バッチ処理 {#batch-processing}

### チャレンジ {#challenge}

大量データ更新、システム移行、ETL ワークフローなどの大規模トランザクションでは、数百万行の処理が必要となり、重要な操作をサポートするために不可欠です。TiDB は分散 SQL データベースとして優れていますが、このようなトランザクションを大規模に処理するには、次の 2 つの大きな課題があります。

-   メモリ制限: TiDB v8.1.0 より前のバージョンでは、トランザクション ライフサイクル全体を通じてすべてのトランザクション変更がメモリ内に保持されるため、リソースに負担がかかり、パフォーマンスが低下します。数百万行に及ぶ操作の場合、メモリ使用量が過剰になり、リソースが不足するとメモリ不足 (OOM) エラーが発生する場合があります。

-   パフォーマンスの低下: 大規模なメモリ内バッファの管理は赤黒木に依存しており、計算オーバーヘッドが発生します。バッファが大きくなると、これらのデータ構造に固有の*O(N log N) の*複雑さにより、操作が遅くなります。

### 解決 {#solution}

これらの課題は、スケーラビリティの向上、複雑さの軽減、信頼性の強化を実現する明確な機会を浮き彫りにしています。現代のデータ ワークロードの増加に伴い、TiDB は、大規模なトランザクションの処理を最適化し、リソースの使用率と全体的なパフォーマンスを向上させるように設計された[パイプライン化された DML](https://docs.pingcap.com/tidb/stable/system-variables#tidb_dml_type-new-in-v800)機能を導入しています。

### テスト環境 {#test-environment}

-   クラスタトポロジ: TiDB (16 vCPU、32 GiB) * 1 + TiKV (16 vCPU、32 GiB) * 3
-   データセット: 1,000 万行 (約 10 GiB のデータ) の YCSB 非クラスター化テーブル。ホットスポット パターンの影響を分離して評価するために、特定のテストでは主キーが選択的に削除されます。
-   `DELETE`ロード: `INSERT` `UPDATE`含む DML 操作。

### テスト結果 {#test-results}

実行速度は 2 倍になり、最大 TiDBメモリ使用量は 50% 減少し、TiKV 書き込みフローはよりスムーズになります。

-   遅延（秒）

    | ワークロード (10 GiB) | 標準 DML | パイプライン化された DML | 改善      |
    | --------------- | ------ | -------------- | ------- |
    | YCSB-挿入-10M     | 368    | 159            | 131.45% |
    | YCSB アップデート 10M | 255    | 131            | 94.66%  |
    | YCSB-削除-10M     | 136    | 42             | 223.81% |

-   TiDBメモリ使用量ピーク (GiB)

    | ワークロード (10 GiB) | 標準 DML | パイプライン化された DML | 削減     |
    | --------------- | ------ | -------------- | ------ |
    | YCSB-挿入-10M     | 25.8   | 12             | 53.49% |
    | YCSB アップデート 10M | 23.1   | 12.9           | 44.16% |
    | YCSB-削除-10M     | 10.1   | 8.08           | 20.00% |

## TiKVスケーリングパフォーマンス {#tikv-scaling-performance}

### チャレンジ {#challenge}

水平スケーリングは TiKV のコア機能であり、必要に応じてシステムをスケールインまたはスケールアウトできます。ビジネス需要が拡大し、テナント数が増加すると、TiDB クラスターのデータベース、テーブル、およびデータ量が急速に増加します。サービス品質を維持するためには、TiKV ノードを迅速にスケールアウトすることが不可欠になります。

シナリオによっては、TiDB が多数のデータベースとテーブルをホストします。これらのテーブルが小さいか空の場合、特にテーブル数が大規模 (100 万以上など) に増えると、TiKV は多数の小さなリージョンを蓄積します。これらの小さなリージョンは、メンテナンスの負担を大きくし、リソースのオーバーヘッドを増加させ、効率を低下させます。

### 解決 {#solution}

この問題に対処するため、TiDB v8.5.0 では、小さなリージョンのマージのパフォーマンスが向上し、内部オーバーヘッドが削減され、リソースの使用率が向上します。さらに、TiDB v8.5.0 には、TiKV スケーリング パフォーマンスをさらに向上させるためのその他の機能強化がいくつか含まれています。

### テスト環境 {#test-environment}

#### 小さな地域の統合 {#merging-small-regions}

-   クラスタトポロジ: TiDB (16 vCPU、32 GiB) * 1 + TiKV (16 vCPU、32 GiB) * 3
-   データセット: 約 100 万個の小さなテーブル (各テーブルのサイズは 2 MiB 未満)
-   ワークロード: 小さなリージョンの自動マージ

#### TiKVノードのスケールアウト {#scaling-out-tikv-nodes}

-   クラスタトポロジ: TiDB (16 vCPU、32 GiB) * 1 + TiKV (16 vCPU、32 GiB) * 4
-   データセット: 20,000 の倉庫を含む TPC-C データセット
-   ワークロード: TiKV ノードを 4 から 7 にスケールアウト

### テスト結果 {#test-results}

小さなリージョンのマージ速度が約 10 倍向上します。

| メトリック         | 改善がなければ | 改善により |
| ------------- | ------- | ----- |
| リージョン統合期間（時間） | 20      | 2     |

TiKV スケーリング パフォーマンスは 40% 以上向上し、TiKV ノードのスケールアウト時間は 30% 短縮されます。

| メトリック               | 改善がなければ | 改善により |
| ------------------- | ------- | ----- |
| TiKV スケールアウト期間 (時間) | 5       | 3.5   |

## ベンチマーク {#benchmark}

前述のテスト データに加えて、v8.5.0 のパフォーマンスに関する次のベンチマーク結果を参照できます。

-   [TPC-C パフォーマンステストレポート](/tidb-cloud/v8.5-performance-benchmarking-with-tpcc.md)
-   [Sysbench パフォーマンステストレポート](/tidb-cloud/v8.5-performance-benchmarking-with-sysbench.md)
