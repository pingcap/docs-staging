---
title: Import Local Files to TiDB Cloud
summary: ローカル ファイルをTiDB Cloudにインポートする方法を学びます。
---

# ローカルファイルをTiDB Cloudにインポートする {#import-local-files-to-tidb-cloud}

ローカル ファイルをTiDB Cloudに直接インポートできます。タスク構成を完了するには数回クリックするだけで、ローカル CSV データが TiDB クラスターにすばやくインポートされます。この方法を使用すると、クラウドstorageバケット パスとロール ARN を指定する必要がありません。インポート プロセス全体が迅速かつスムーズになります。

現在、この方法では、1 つのタスクに対して 1 つの CSV ファイルを既存のテーブルまたは新しいテーブルにインポートすることがサポートされています。

## 制限事項 {#limitations}

-   現在、 TiDB Cloud は1 つのタスクにつき 50 MiB 以内の CSV 形式のローカル ファイルのインポートのみをサポートしています。
-   ローカル ファイルのインポートは、TiDB サーバーレス クラスターでのみサポートされ、TiDB 専用クラスターではサポートされません。
-   複数のインポート タスクを同時に実行することはできません。
-   CSV ファイルをTiDB Cloudの既存のテーブルにインポートし、ターゲット テーブルにソース ファイルよりも多くの列がある場合、状況に応じて余分な列が異なって処理されます。
    -   追加の列が主キーまたは一意のキーでない場合は、エラーは報告されません。代わりに、これらの追加の列には[デフォルト値](/data-type-default-values.md)入力されます。
    -   追加の列が主キーまたは一意のキーであり、属性`auto_increment`または`auto_random`を持たない場合は、エラーが報告されます。その場合は、次のいずれかの戦略を選択することをお勧めします。
        -   これらの主キーまたは一意のキー列を含むソース ファイルを提供します。
        -   主キーまたは一意キー列の属性を`auto_increment`または`auto_random`に設定します。
-   列名が TiDB で予約済みの[キーワード](/keywords.md)である場合、 TiDB Cloud は自動的にバックティック`` ` ``を追加して列名を囲みます。たとえば、列名が`order`の場合、 TiDB Cloud は自動的にバックティック`` ` ``を追加して`` `order` ``に変更し、データをターゲット テーブルにインポートします。

## ローカルファイルをインポートする {#import-local-files}

1.  ターゲット クラスターの**インポート**ページを開きます。

    1.  [TiDB Cloudコンソール](https://tidbcloud.com/)にログインし、プロジェクトの[**クラスター**](https://tidbcloud.com/console/clusters)ページに移動します。

        > **ヒント：**
        >
        > 複数のプロジェクトがある場合は、<mdsvgicon name="icon-left-projects">左下隅にある をクリックして、別のプロジェクトに切り替えます。</mdsvgicon>

    2.  ターゲット クラスターの名前をクリックして概要ページに移動し、左側のナビゲーション ペインで**[インポート] を**クリックします。

2.  **インポート**ページでは、ローカルファイルをアップロードエリアに直接ドラッグアンドドロップするか、アップロードエリアをクリックして対象のローカルファイルを選択してアップロードすることができます。1 つのタスクにつき 50 MiB 未満の CSV ファイルを 1 つだけアップロードできることに注意してください。ローカルファイルが 50 MiB より大きい場合は、 [50 MiB を超えるローカル ファイルをインポートするにはどうすればよいでしょうか?](#how-to-import-a-local-file-larger-than-50-mib)を参照してください。

3.  **[ターゲット]**領域で、ターゲット データベースとターゲット テーブルを選択するか、名前を直接入力して新しいデータベースまたは新しいテーブルを作成します。名前は文字 (az と AZ) または数字 (0-9) で始まる必要があり、文字 (az と AZ)、数字 (0-9)、およびアンダースコア (_) 文字を含めることができます。 **[プレビュー**] をクリックします。

4.  表を確認してください。

    設定可能なテーブル列のリストが表示されます。各行には、 TiDB Cloudによって推測されたテーブル列名、推測されたテーブル列タイプ、および CSV ファイルからプレビューされたデータが表示されます。

    -   TiDB Cloudの既存のテーブルにデータをインポートすると、テーブル定義から列リストが抽出され、プレビューされたデータが列名によって対応する列にマッピングされます。

    -   新しいテーブルを作成する場合は、CSV ファイルから列リストを抽出し、 TiDB Cloudによって列の型が推測されます。たとえば、プレビューされたデータがすべて整数の場合、推測される列の型は**int** (整数) になります。

5.  列名とデータ型を構成します。

    CSV ファイルの最初の行に列名が記録されている場合は、デフォルトで選択されている「**最初の行を列名として使用する」が**選択されていることを確認します。

    CSV ファイルに列名用の行がない場合は、 **「最初の行を列名として使用」**を選択しないでください。この場合、次のようになります。

    -   ターゲット テーブルがすでに存在する場合、CSV ファイル内の列が順番にターゲット テーブルにインポートされます。余分な列は切り捨てられ、不足している列にはデフォルト値が設定されます。

    -   TiDB Cloud を使用してターゲット テーブルを作成する必要がある場合は、各列の名前を入力します。列名は次の要件を満たす必要があります。

        -   名前は、文字 (az と AZ)、数字 (0-9)、記号 (中国語や日本語など)、およびアンダースコア ( `_` ) 文字のみで構成する必要があります。
        -   その他の特殊文字はサポートされていません。
        -   名前の長さは 65 文字未満にする必要があります。

        必要に応じてデータ型を変更することもできます。

6.  新しいターゲット テーブルでは、主キーを設定できます。主キーとして列を選択するか、複数の列を選択して複合主キーを作成できます。複合主キーは、列名を選択した順序で形成されます。

    > **注記：**
    >
    > -   テーブルの主キーはクラスター化インデックスであり、作成後に削除することはできません。
    > -   主キー フィールドに対応するデータが一意であり、空でないことを確認してください。そうでない場合、インポート タスクでデータの不整合が発生します。

7.  必要に応じて CSV 構成を編集します。

    また、 **「CSV 構成の編集」を**クリックして、バックスラッシュ エスケープ、セパレーター、および区切り文字を構成し、よりきめ細かな制御を行うこともできます。CSV 構成の詳細については、 [データをインポートするための CSV 構成](/tidb-cloud/csv-config-for-import-data.md)を参照してください。

8.  **プレビュー**ページでは、データをプレビューできます。**インポートの開始を**クリックします。

    **インポート タスクの詳細**ページでインポートの進行状況を確認できます。警告や失敗したタスクがある場合は、詳細を確認して解決できます。

9.  インポート タスクが完了したら、 **[SQL エディターでデータを探索] を**クリックして、インポートしたデータを照会できます。SQL エディターの使用方法の詳細については、 [AI支援SQLエディターでデータを探索](/tidb-cloud/explore-data-with-chat2query.md)を参照してください。

10. **[インポート]**ページで、 **[アクション]**列の**[ビュー] を**クリックすると、インポート タスクの詳細を確認できます。

## FAQ {#faq}

### TiDB Cloudのインポート機能を使用して、指定した列のみをインポートできますか? {#can-i-only-import-some-specified-columns-by-the-import-feature-in-tidb-cloud}

いいえ。現在、インポート機能を使用する場合、CSV ファイルのすべての列を既存のテーブルにインポートすることしかできません。

指定した列のみをインポートするには、MySQL クライアントを使用して TiDB クラスターに接続し、 [`LOAD DATA`](https://docs.pingcap.com/tidb/stable/sql-statement-load-data)使用してインポートする列を指定します。例:

```sql
CREATE TABLE `import_test` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(64) NOT NULL,
  `address` varchar(64) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;
LOAD DATA LOCAL INFILE 'load.txt' INTO TABLE import_test FIELDS TERMINATED BY ',' (name, address);
```

`mysql`使用していて`ERROR 2068 (HY000): LOAD DATA LOCAL INFILE file request rejected due to restrictions on access.`に遭遇した場合は、接続文字列に`--local-infile=true`追加できます。

### TiDB Cloudにデータをインポートした後、予約キーワードを含む列をクエリできないのはなぜですか? {#why-can-t-i-query-a-column-with-a-reserved-keyword-after-importing-data-into-tidb-cloud}

列名が TiDB で予約済みの[キーワード](/keywords.md)である場合、 TiDB Cloud は自動的にバックティック`` ` ``を追加して列名を囲み、データをターゲット テーブルにインポートします。列をクエリするときは、バックティック`` ` ``を追加して列名を囲む必要があります。たとえば、列名が`order`の場合、 `` `order` ``を使用して列をクエリする必要があります。

### 50 MiB を超えるローカル ファイルをインポートするにはどうすればよいでしょうか? {#how-to-import-a-local-file-larger-than-50-mib}

ファイルが 50 MiB より大きい場合は、 `split [-l ${line_count}]`ユーティリティを使用して、ファイルを複数の小さなファイルに分割できます (Linux または macOS のみ)。たとえば、 `split -l 100000 tidb-01.csv small_files`実行すると、 `tidb-01.csv`という名前のファイルが行の長さ`100000`で分割され、分割されたファイルの名前は`small_files${suffix}`なります。その後、これらの小さなファイルを 1 つずつTiDB Cloudにインポートできます。

次のスクリプトを参照してください。

```bash
#!/bin/bash
n=$1
file_path=$2
file_extension="${file_path##*.}"
file_name="${file_path%.*}"
total_lines=$(wc -l < $file_path)
lines_per_file=$(( (total_lines + n - 1) / n ))
split -d -a 1 -l $lines_per_file $file_path $file_name.
for (( i=0; i<$n; i++ ))
do
    mv $file_name.$i $file_name.$i.$file_extension
done
```

`n`とファイル名を入力してスクリプトを実行します。スクリプトは元のファイル拡張子を維持しながらファイルを`n`均等な部分に分割します。例:

```bash
> sh ./split.sh 3 mytest.customer.csv
> ls -h | grep mytest
mytest.customer.0.csv
mytest.customer.1.csv
mytest.customer.2.csv
mytest.customer.csv
```
