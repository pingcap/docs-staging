---
title: Key Metrics on Performance Overview
summary: パフォーマンス概要ダッシュボードに表示される主要な指標を確認します。
---

# パフォーマンス概要の主要指標 {#key-metrics-on-performance-overview}

TiUPを使用して TiDB クラスターをデプロイすると、監視システム (Prometheus および Grafana) も同時にデプロイされます。詳細については、 [TiDB 監視フレームワークの概要](/tidb-monitoring-framework.md)参照してください。

Grafana ダッシュボードは、PD、TiDB、TiKV、Node_exporter、概要、パフォーマンス概要を含む一連のサブダッシュボードに分かれています。診断に役立つ多くのメトリックがあります。

パフォーマンス概要ダッシュボードは、TiDB、PD、および TiKV のメトリックを調整し、それぞれを次のセクションで表示します。

-   概要: データベース時間と SQL 実行時間の概要。概要でさまざまな色を確認することで、データベースのワークロード プロファイルとパフォーマンスのボトルネックをすばやく特定できます。

-   負荷プロファイル: データベース QPS、接続情報、アプリケーションが TiDB と対話する MySQL コマンド タイプ、データベース内部 TSO および KV 要求 OPS、TiKV および TiDB のリソース使用量などの主要なメトリックとリソース使用量。

-   トップダウンのレイテンシーの内訳: クエリレイテンシーと接続アイドル時間の比率、クエリレイテンシーの内訳、実行中の TSO/KV 要求レイテンシー、TiKV 内の書き込みレイテンシーの内訳。

パフォーマンス概要ダッシュボードを使用すると、パフォーマンスを効率的に分析し、ユーザー応答時間のボトルネックがデータベースにあるかどうかを確認できます。ボトルネックがデータベースにある場合は、データベース時間の概要、ワークロード プロファイル、SQLレイテンシーの内訳を使用して、データベース内のボトルネックを特定できます。詳細については、 [パフォーマンス分析とチューニング](/performance-tuning-methods.md)を参照してください。

次のセクションでは、パフォーマンス概要ダッシュボードのメトリックについて説明します。

## パフォーマンスの概要 {#performance-overview}

### SQL タイプ別のデータベース時間 {#database-time-by-sql-type}

-   データベース時間: 1秒あたりの合計データベース時間
-   sql_type: 1 秒あたりに各タイプの SQL ステートメントによって消費されるデータベース時間

### SQL フェーズ別のデータベース時間 {#database-time-by-sql-phase}

-   データベース時間: 1秒あたりの合計データベース時間
-   トークンの取得/解析/コンパイル/実行: 4 つの SQL 処理フェーズで消費されるデータベース時間

全体的に、SQL 実行フェーズは緑色で、他のフェーズは赤色で表示されます。緑色以外の領域が大きい場合は、実行フェーズ以外のフェーズで多くのデータベース時間が消費されていることを意味し、さらに原因分析が必要です。

### SQL 実行時間の概要 {#sql-execute-time-overview}

-   実行時間: SQL 実行中に 1 秒あたりに消費されるデータベース時間
-   tso_wait: SQL 実行中の 1 秒あたりの同時 TSO 待機時間
-   kv 要求タイプ: SQL 実行中に 1 秒あたりに各 KV 要求タイプを待機する時間。KV 要求は同時であるため、合計 KV 要求待機時間は SQL 実行時間を超える場合があります。
-   tiflash_mpp: SQL 実行中に 1 秒あたりにTiFlash要求を処理する時間。

緑のメトリックは一般的な KV 書き込み要求 (事前書き込みやコミットなど) を表し、青のメトリックは一般的な読み取り要求を表し、紫のメトリックはTiFlash MPP 要求を表し、他の色のメトリックは注意を払う必要がある予期しない状況を表します。たとえば、悲観的ロック KV 要求は赤でマークされ、TSO 待機は濃い茶色でマークされます。

青以外の領域や緑以外の領域が大きい場合は、SQL 実行中にボトルネックが発生していることを意味します。例:

-   重大なロック競合が発生した場合、赤い領域が大きな割合を占めることになります。
-   TSO の待機に過剰な時間が費やされると、濃い茶色の領域が大きな割合を占めることになります。

### 品質保証 {#qps}

すべての TiDB インスタンスで 1 秒あたりに実行された SQL ステートメントの数 (タイプ別に収集`INSERT` : `SELECT` `UPDATE`

### タイプ別CPS {#cps-by-type}

タイプに基づいて、すべての TiDB インスタンスによって 1 秒あたりに処理されるコマンドの数

### プランキャッシュ OPS を使用したクエリ {#queries-using-plan-cache-ops}

-   avg-hit: すべての TiDB インスタンスで 1 秒あたりに実行プラン キャッシュを使用するクエリの数
-   avg-miss: すべての TiDB インスタンスで実行プラン キャッシュを使用していないクエリの数 (1 秒あたり)

`avg-hit + avg-miss`は`StmtExecute`に等しく、これは 1 秒あたりに実行されるすべてのクエリの数です。

### KV/TSO リクエスト OPS {#kv-tso-request-ops}

-   kv リクエスト合計: すべての TiDB インスタンスにおける 1 秒あたりの KV リクエストの合計数
-   タイプ別の KV 要求: `Get` 、 `Prewrite` 、 `Commit`などのタイプに基づく、すべての TiDB インスタンスでの 1 秒あたりの KV 要求の数。
-   tso - cmd: すべての TiDB インスタンスにおける`tso cmd`秒あたりのリクエスト数
-   tso - リクエスト: すべての TiDB インスタンスにおける`tso request`秒あたりのリクエスト数

通常、 `tso - cmd` `tso - request`で割ると、1 秒あたりのリクエストの平均バッチ サイズが得られます。

### ソース別の KV 要求時間 {#kv-request-time-by-source}

-   kv リクエスト合計時間: すべての TiDB インスタンスで 1 秒あたりに KV およびTiFlashリクエストを処理する合計時間
-   各 KV リクエストと対応するリクエスト ソースは積み上げ棒グラフを形成し、 `external`通常のビジネス リクエストを識別し、 `internal`内部アクティビティ リクエスト (DDL やauto analyzeリクエストなど) を識別します。

### TiDB CPU {#tidb-cpu}

-   avg: すべての TiDB インスタンスの平均 CPU 使用率
-   デルタ: すべての TiDB インスタンスの最大 CPU 使用率からすべての TiDB インスタンスの最小 CPU 使用率を引いた値
-   max: すべての TiDB インスタンスの最大 CPU 使用率

### TiKV CPU/IO MBps {#tikv-cpu-io-mbps}

-   CPU-Avg: すべての TiKV インスタンスの平均 CPU 使用率
-   CPU デルタ: すべての TiKV インスタンスの最大 CPU 使用率からすべての TiKV インスタンスの最小 CPU 使用率を引いた値
-   CPU-MAX: すべての TiKV インスタンス間の最大 CPU 使用率
-   IO-Avg: すべての TiKV インスタンスの平均 MBps
-   IO-Delt: すべての TiKV インスタンスの最大 MBps からすべての TiKV インスタンスの最小 MBps を引いた値
-   IO-MAX: すべての TiKV インスタンスの最大 MBps

### 間隔 {#duration}

-   所要時間: 実行時間

    -   クライアントから TiDB へのリクエストを受信して​​から、TiDB がリクエストを実行し、結果をクライアントに返すまでの期間。通常、クライアント リクエストは SQL ステートメントの形式で送信されますが、この期間には`COM_PING` 、 `COM_SLEEP` 、 `COM_STMT_FETCH` 、 `COM_SEND_LONG_DATA`などのコマンドの実行時間が含まれる場合があります。
    -   TiDB はマルチクエリをサポートしています。つまり、クライアントは一度に複数の SQL ステートメント (例: `select 1; select 1; select 1;`を送信できます。この場合、このクエリの合計実行時間には、すべての SQL ステートメントの実行時間が含まれます。

-   平均: すべてのリクエストを実行する平均時間

-   99: すべてのリクエストを実行するための P99 期間

-   タイプ別の平均: すべての TiDB インスタンスですべてのリクエストを実行する平均時間 (タイプ`SELECT` `UPDATE`収集`INSERT`

### 接続アイドル時間 {#connection-idle-duration}

接続アイドル期間は、接続がアイドル状態になっている期間を示します。

-   avg-in-txn: トランザクション内の接続の平均アイドル時間
-   avg-not-in-txn: 接続がトランザクション内にない場合の平均接続アイドル時間
-   99-in-txn: 接続がトランザクション内にある場合の P99 接続アイドル期間

### 接続数 {#connection-count}

-   合計: すべての TiDB インスタンスへの接続数
-   アクティブな接続: すべての TiDB インスタンスへのアクティブな接続の数
-   tidb-{node-number}-peer: 各 TiDB インスタンスへの接続数
-   切断/秒: TiDB クラスター内の切断回数
-   99-not-in-txn: 接続がトランザクション内にない場合の P99 接続アイドル期間

### 解析期間、コンパイル期間、実行期間 {#parse-duration-compile-duration-and-execute-duration}

-   解析時間: SQL 文の解析に要した時間
-   コンパイル時間: 解析された SQL AST を実行プランにコンパイルするのにかかる時間
-   実行時間: SQL文の実行計画の実行に費やされた時間

これら 3 つのメトリックにはすべて、すべての TiDB インスタンスの平均期間と 99 パーセンタイル期間が含まれます。

### 平均 TiDB KV リクエスト期間 {#avg-tidb-kv-request-duration}

`Get` 、 `Prewrite` 、 `Commit`などのタイプに基づいて、すべての TiDB インスタンスで KV 要求を実行するのに費やされた平均時間。

### 平均 TiKV GRPC 期間 {#avg-tikv-grpc-duration}

`kv_get` 、 `kv_prewrite` 、 `kv_commit`などのタイプに基づいて、すべての TiKV インスタンスで gRPC リクエストを実行するのに費やされた平均時間。

### PD TSO 待機/RPC 期間 {#pd-tso-wait-rpc-duration}

-   wait - avg: すべての TiDB インスタンスで PD が TSO を返すのを待つ平均時間
-   rpc - 平均: PD に TSO 要求を送信してからすべての TiDB インスタンスで TSO を受信するまでの平均時間
-   wait - 99: すべての TiDB インスタンスで PD が TSO を返すのを待つ P99 時間
-   rpc - 99: PD に TSO 要求を送信してからすべての TiDB インスタンスで TSO を受信するまでの P99 時間

### ストレージ非同期書き込み期間、保存期間、適用期間 {#storage-async-write-duration-store-duration-and-apply-duration}

-   ストレージ非同期書き込み時間: 非同期書き込みにかかる時間
-   ストア期間: 非同期書き込み中にストアループで消費される時間
-   適用期間: 非同期書き込み中の適用ループで消費される時間

これら 3 つのメトリックには、すべての TiKV インスタンスの平均期間と P99 期間が含まれます。

平均storage非同期書き込み時間 = 平均保存時間 + 平均適用時間

### 追加ログ期間、コミットログ期間、適用ログ期間 {#append-log-duration-commit-log-duration-and-apply-log-duration}

-   ログ追加時間: Raftがログを追加するのにかかる時間
-   コミットログ期間: Raftがログをコミットするのにかかる時間
-   ログ適用期間: Raftがログを適用するのにかかる時間

これら 3 つのメトリックには、すべての TiKV インスタンスの平均期間と P99 期間が含まれます。

### パフォーマンス概要パネルのインターフェース {#interface-of-the-performance-overview-panels}

![performance overview](https://download.pingcap.com/images/docs/performance/grafana_performance_overview.png)

## TiFlash {#tiflash}

-   CPU: TiFlashインスタンスごとの CPU 使用率。
-   メモリ: TiFlashインスタンスごとのメモリ使用量。
-   IO 使用率: TiFlashインスタンスごとの IO 使用率。
-   MPP クエリ数: TiFlashインスタンスごとの 1 秒あたりのTiFlash MPP クエリ数。
-   リクエスト QPS: すべてのTiFlashインスタンスによって受信されたコプロセッサ要求の数。

    -   `batch` : バッチリクエストの数。
    -   `batch_cop` : バッチ要求内のコプロセッサ要求の数。
    -   `cop` : コプロセッサ インターフェイスを介して直接送信されるコプロセッサ要求の数。
    -   `cop_dag` : すべてのコプロセッサ要求内の DAG 要求の数。
    -   `super_batch` : スーパーバッチ機能を有効にするリクエストの数。
-   Executor QPS: すべてのTiFlashインスタンスが受信したリクエスト内の各タイプの DAG Executor の数`table_scan`はテーブル スキャン Executor です`selection`は選択 Executor です`aggregation`は集約 Executor です`top_n`は`TopN` Executor です`limit`は制限 Executor です。
-   リクエスト期間の概要: すべてのTiFlashインスタンスのすべてのリクエスト タイプについて、1 秒あたりの合計処理時間の積み上げグラフを提供します。
-   要求期間: すべてのTiFlashインスタンスにおける各 MPP およびコプロセッサ要求タイプの合計処理期間。これは、コプロセッサ要求が受信された時間から要求の応答が完了するまでの時間であり、平均レイテンシーと p99レイテンシーが含まれます。
-   リクエスト処理期間: すべてのTiFlashインスタンスにおける各 MPP およびコプロセッサ リクエスト タイプの実際の処理期間。これは、コプロセッサ リクエストの実行開始から実行完了までの期間で、平均レイテンシーと p99レイテンシーが含まれます。
-   Raft待機インデックス期間: すべてのTiFlashインスタンスに対して`wait_index`が使用する時間、つまり、 `read_index`要求を受信して​​からリージョンインデックス &gt;= `read_index`になるまで待機するために使用される時間。
-   Raftバッチ読み取りインデックス期間: すべてのTiFlashインスタンスに対して`read_index`が使用する時間。ほとんどの時間は、リージョンリーダーとのやり取りと再試行に使用されます。
-   インスタンスごとの書き込みスループット: インスタンスごとの書き込みのスループット。これには、 Raft書き込みコマンドとRaftスナップショットを適用した場合のスループットが含まれます。
-   書き込みフロー: すべてのTiFlashインスタンスによるディスク書き込みのトラフィック。
-   読み取りフロー: すべてのTiFlashインスタンスによるディスク読み取りのトラフィック。

## CDC {#cdc}

-   CPU 使用率: TiCDC ノードごとの CPU 使用率。
-   メモリ使用量: TiCDC ノードごとのメモリ使用量。
-   Goroutine 数: TiCDC ノードあたりの Goroutine の数。
-   Changefeed チェックポイント ラグ: アップストリームとダウンストリーム間のデータ レプリケーションの進行ラグ (単位は秒)。
-   Changefeed 解決 ts ラグ: アップストリーム ノードと TiCDC ノード間のデータ複製の進行ラグ (単位は秒)。
-   チェンジフィードのステータス:

    -   0: 正常
    -   1: エラー
    -   2: 失敗
    -   3: 停止
    -   4: 完了
    -   -1: 不明
-   Puller 出力イベント/秒: TiCDC ノードの Puller モジュールが Sorter モジュールに 1 秒あたりに送信する行数。
-   ソーター出力イベント/秒: TiCDC ノードのソーター モジュールがマウント モジュールに 1 秒あたりに送信する行数。
-   マウンター出力イベント/秒: TiCDC ノードのマウンター モジュールがシンク モジュールに 1 秒あたりに送信する行数。
-   テーブル シンク出力イベント/秒: TiCDC ノードのテーブル ソーター モジュールがシンク モジュールに 1 秒あたりに送信する行数。
-   SinkV2 - シンク フラッシュ行数/秒: TiCDC ノードのシンク モジュールがダウンストリームに 1 秒あたりに送信する行数。
-   トランザクションシンクの完全フラッシュ期間: TiCDC ノードの MySQL シンクによるダウンストリーム トランザクションの書き込みの平均レイテンシーと p999レイテンシー。
-   MQ ワーカーのメッセージ送信期間パーセンタイル: ダウンストリームが Kafka の場合の MQ ワーカーによるメッセージ送信のレイテンシー。
-   Kafka 送信バイト: MQ ワークロードでのダウンストリーム トランザクションの書き込みトラフィック。
