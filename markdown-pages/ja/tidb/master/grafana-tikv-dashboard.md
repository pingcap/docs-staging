---
title: Key Monitoring Metrics of TiKV
summary: Grafana TiKV ダッシュボードに表示されるいくつかの主要なメトリックについて学習します。
---

# TiKVの主要な監視指標 {#key-monitoring-metrics-of-tikv}

TiUPを使用して TiDB クラスターをデプロイすると、監視システム (Prometheus/Grafana) も同時にデプロイされます。詳細については、 [監視フレームワークの概要](/tidb-monitoring-framework.md)参照してください。

Grafana ダッシュボードは、Overview、PD、TiDB、TiKV、Node_exporter、Performance_overview などの一連のサブダッシュボードに分かれています。診断に役立つメトリックが多数あります。

## TiKV詳細ダッシュボード {#tikv-details-dashboard}

主要なメトリックが表示される**TiKV-Details**ダッシュボードから、コンポーネントTiKV ステータスの概要を取得できます。 [パフォーマンスマップ](https://asktug.com/_/tidb-performance-map/#/)に従って、クラスターのステータスが期待どおりであるかどうかを確認できます。

このセクションでは**、TiKV-Details**ダッシュボード上のこれらの主要なメトリックについて詳しく説明します。

### クラスタ {#cluster}

-   ストアサイズ: TiKVインスタンスあたりのstorageサイズ
-   利用可能なサイズ: TiKVインスタンスあたりの利用可能な容量
-   容量サイズ: TiKVインスタンスあたりの容量サイズ
-   CPU: TiKVインスタンスごとのCPU使用率
-   メモリ: TiKVインスタンスごとのメモリ使用量
-   IO使用率: TiKVインスタンスあたりのI/O使用率
-   MBps: 各 TiKV インスタンスの読み取りと書き込みの合計バイト数
-   QPS: 各 TiKV インスタンスのコマンドあたりの QPS
-   Errps: gRPC メッセージの失敗率
-   リーダー: TiKVインスタンスあたりのリーダーの数
-   リージョン: TiKVインスタンスあたりのリージョン数
-   稼働時間: 前回の再起動以降の TiKV の実行時間

![TiKV Dashboard - Cluster metrics](https://download.pingcap.com/images/docs/tikv-dashboard-cluster.png)

### エラー {#errors}

-   重大なエラー: 重大なエラーの数
-   サーバーがビジー: 書き込みストールやチャネル フルなど、TiKV インスタンスを一時的に使用不可にするイベントの発生を示します。通常の場合は`0`になります。
-   サーバー レポートの失敗:サーバーによって報告されたエラー メッセージの数。通常は`0`なります。
-   Raftstoreエラー: 各 TiKV インスタンスのタイプごとのRaftstoreエラーの数
-   スケジューラ エラー: 各 TiKV インスタンスのタイプごとのスケジューラ エラーの数
-   コプロセッサーエラー: 各 TiKV インスタンスのタイプごとのコプロセッサ エラーの数
-   gRPC メッセージ エラー: 各 TiKV インスタンスのタイプごとの gRPC メッセージ エラーの数
-   Leaderドロップ: TiKVインスタンスごとにドロップされたリーダーの数
-   Leaderが欠落している: TiKVインスタンスごとに欠落しているリーダーの数
-   ログレプリケーション拒否: 各 TiKV インスタンスのメモリ不足により拒否された logappend メッセージの数

![TiKV Dashboard - Errors metrics](https://download.pingcap.com/images/docs/tikv-dashboard-errors-v610.png)

### サーバ {#server}

-   CFサイズ: 各カラムファミリーのサイズ
-   ストアサイズ: TiKVインスタンスあたりのstorageサイズ
-   チャネル フル: TiKV インスタンスごとのチャネル フル エラーの数。通常は`0`になります。
-   アクティブな書き込みリーダー: 各 TiKV インスタンスに書き込まれているリーダーの数
-   おおよそのリージョンサイズ: おおよそのリージョンサイズ
-   おおよそのリージョンサイズのヒストグラム: 各おおよそのリージョンサイズのヒストグラム
-   リージョン平均書き込みキー: TiKV インスタンスあたりのリージョンへの平均書き込みキー数
-   リージョン平均書き込みバイト数: TiKVインスタンスあたりのリージョンへの平均書き込みバイト数

![TiKV Dashboard - Server metrics](https://download.pingcap.com/images/docs/tikv-dashboard-server.png)

### GRPC とは {#grpc}

-   gRPC メッセージ数: タイプごとの gRPC メッセージの割合
-   gRPC メッセージが失敗しました: 失敗した gRPC メッセージの割合
-   99% gRPC メッセージ継続時間: メッセージ タイプごとの gRPC メッセージ継続時間 (P99)
-   平均gRPCメッセージ期間: gRPCメッセージの平均実行時間
-   gRPC バッチ サイズ: TiDB と TiKV 間の gRPC メッセージのバッチ サイズ
-   Raftメッセージのバッチサイズ: TiKVインスタンス間のRaftメッセージのバッチサイズ
-   gRPC リクエストソースの QPS: gRPC リクエストソースの QPS
-   gRPC リクエストソースの継続時間: gRPC リクエストソースの実行時間
-   gRPC リソース グループの QPS: リソース グループ別の gRPC リクエスト ソースの QPS

### スレッドCPU {#thread-cpu}

-   Raftストア CPU: `raftstore`スレッドの CPU 使用率。通常の場合、CPU 使用率は 80% * `raftstore.store-pool-size`未満である必要があります。
-   非同期適用 CPU: `async apply`スレッドの CPU 使用率。通常の場合、CPU 使用率は 90% * `raftstore.apply-pool-size`未満である必要があります。
-   ストアライターCPU: 非同期IOスレッドのCPU使用率。通常の場合、CPU使用率は90%* `raftstore.store-io-pool-size`未満である必要があります。
-   gRPC ポーリング CPU: `gRPC`スレッドの CPU 使用率。通常の場合、CPU 使用率は 80% * `server.grpc-concurrency`未満である必要があります。
-   スケジューラ ワーカー CPU: `scheduler worker`スレッドの CPU 使用率。通常の場合、CPU 使用率は 90% * `storage.scheduler-worker-pool-size`未満である必要があります。
-   ストレージReadPool CPU: `storage read pool`スレッドのCPU使用率
-   統合読み取りプールCPU: `unified read pool`スレッドのCPU使用率
-   RocksDB CPU: RocksDBスレッドのCPU使用率
-   コプロセッサーCPU: `coprocessor`スレッドのCPU使用率
-   GCワーカーCPU: `GC worker`スレッドのCPU使用率
-   バックグラウンドワーカーCPU: `background worker`スレッドのCPU使用率
-   インポートCPU: `import`スレッドのCPU使用率
-   バックアップワーカーCPU: `backup`スレッドのCPU使用率
-   CDCワーカーCPU: `CDC worker`スレッドのCPU使用率
-   CDCエンドポイントCPU: `CDC endpoint`スレッドのCPU使用率
-   Raftlog フェッチワーカー CPU: 非同期 raft ログフェッチャーワーカーの CPU 使用率
-   TSOワーカーCPU: `TSO worker`スレッドのCPU使用率

### PD {#pd}

-   PDリクエスト: TiKVがPDに送信するレート
-   PDリクエスト期間（平均）：TiKVがPDに送信するリクエストの処理にかかる平均期間
-   PD ハートビート: TiKV から PD にハートビートメッセージが送信される速度
-   PD 検証ピア: TiKV ピアを検証するために TiKV から PD にメッセージが送信される速度

### RaftIO {#raft-io}

-   ログ適用期間: Raft がログを適用するのにかかる時間
-   サーバーごとのログ適用期間: TiKVインスタンスごとにRaftがログを適用するのにかかる時間
-   ログ追加時間: Raft がログを追加するのにかかる時間
-   サーバーごとのログ追加時間: TiKVインスタンスごとにRaftがログを追加するのにかかる時間
-   コミットログ期間: Raftがログをコミットするのにかかる時間
-   サーバーごとのコミットログ期間: TiKVインスタンスごとにRaftがログをコミットするのにかかる時間

![TiKV Dashboard - Raft IO metrics](https://download.pingcap.com/images/docs/tikv-dashboard-raftio.png)

### Raftプロセス {#raft-process}

-   処理済み準備完了: 1 秒あたりに処理された準備完了操作の数
    -   count: 1秒あたりに処理された準備操作の数
    -   has_ready_region: 1秒あたりに準備完了したリージョンの数
    -   pending_region: 準備完了かどうかをチェックしているリージョンの 1 秒あたりの操作数。このメトリックは v3.0.0 以降非推奨です。
    -   メッセージ: 1秒あたりの準備操作に含まれるメッセージの数
    -   append: 1秒あたりの準備操作に含まれるRaftログエントリの数
    -   コミット: 1秒あたりの準備操作に含まれるコミットされたRaftログエントリの数
    -   スナップショット: 1秒あたりの準備操作に含まれるスナップショットの数
-   0.99 Raftストア イベントの期間: Raftstoreイベントによって消費される時間 (P99)
-   プロセス準備時間: Raftでプロセスが準備完了するまでにかかる時間
-   サーバーごとのプロセス準備時間: TiKV インスタンスごとにRaftでピア プロセスが準備されるまでにかかる時間。2 秒未満 (P99.99) である必要があります。
-   Raftストア イベントの最大期間: 最も遅いRaftstoreイベントによって消費される時間。
-   レプリカ読み取りロック チェック期間: レプリカ読み取りの処理時にロックのチェックにかかる時間。
-   ピア メッセージの長さの分布: 各 TiKV インスタンスの各リージョンで一度に処理されるメッセージの数。メッセージが多いほど、ピアはビジー状態になります。

![TiKV Dashboard - Raft process metrics](https://download.pingcap.com/images/docs/tikv-dashboard-raft-process.png)

### Raftメッセージ {#raft-message}

-   サーバーあたりの送信メッセージ数: 各 TiKV インスタンスが 1 秒あたりに送信するRaftメッセージの数
-   サーバーごとのフラッシュメッセージ: 各 TiKV インスタンスでRaftクライアントによって 1 秒あたりにフラッシュされるRaftメッセージの数
-   サーバーあたりの受信メッセージ数: 各 TiKV インスタンスが 1 秒あたりに受信するRaftメッセージの数
-   メッセージ: 1 秒あたりに送信されたRaftメッセージの数
-   投票: Raftで 1 秒あたりに送信された投票メッセージの数
-   Raftドロップメッセージ: 1 秒あたりの種類ごとのドロップされたRaftメッセージの数

![TiKV Dashboard - Raft message metrics](https://download.pingcap.com/images/docs/tikv-dashboard-raft-message.png)

### Raft提案 {#raft-propose}

-   準備完了ごとのRaft適用提案: 提案を適用中に各準備完了操作がバッチ内に含める提案の数のヒストグラム。
-   Raft の読み取り/書き込み提案: 1 秒あたりのタイプごとの提案数
-   サーバーごとのRaft読み取り提案: 各 TiKV インスタンスが 1 秒あたりに行う読み取り提案の数
-   サーバーごとのRaft書き込み提案: 各 TiKV インスタンスが 1 秒あたりに行う書き込み提案の数
-   提案の待機時間: 各提案の待機時間のヒストグラム
-   サーバーごとの提案待機時間: TiKVインスタンスごとの各提案の待機時間のヒストグラム
-   適用待ち時間: 各提案の適用時間のヒストグラム
-   サーバーごとの適用待機時間: TiKVインスタンスごとの各提案の適用時間のヒストグラム
-   Raft速度: ピアがログを提案する平均速度

![TiKV Dashboard - Raft propose metrics](https://download.pingcap.com/images/docs/tikv-dashboard-raft-propose.png)

### Raft管理者 {#raft-admin}

-   管理者提案: 1秒あたりの管理者提案の数
-   管理者適用: 1 秒あたりに処理された適用コマンドの数
-   チェック分割: 1秒あたりのRaftstore分割チェックコマンドの数
-   99.99% チェック分割期間: 分割チェックコマンドの実行にかかる時間 (P99.99)

![TiKV Dashboard - Raft admin metrics](https://download.pingcap.com/images/docs/tikv-dashboard-raft-admin.png)

### 地元の読者 {#local-reader}

-   ローカル リーダー リクエスト: ローカル リーダー スレッドからの合計リクエスト数と拒否数

![TiKV Dashboard - Local reader metrics](https://download.pingcap.com/images/docs/tikv-dashboard-local-reader.png)

### 統合読み取りプール {#unified-read-pool}

-   レベル別の使用時間: 統合読み取りプール内の各レベルで消費された時間。レベル 0 は小さなクエリを意味します。
-   レベル 0 の可能性: 統合読み取りプール内のレベル 0 タスクの割合
-   実行中のタスク: 統合読み取りプールで同時に実行されているタスクの数

### ストレージ {#storage}

-   ストレージコマンド合計: 1秒あたりのタイプ別受信コマンド数
-   ストレージ非同期リクエストエラー: 1 秒あたりのエンジン非同期リクエストエラーの数
-   ストレージ非同期スナップショット期間: 非同期スナップショット要求の処理にかかる時間。3 `.99`の`1s`未満である必要があります。
-   ストレージ非同期書き込み期間: 非同期書き込み要求の処理にかかる時間。3 `.99`の`1s`未満である必要があります。

![TiKV Dashboard - Storage metrics](https://download.pingcap.com/images/docs/tikv-dashboard-storage.png)

### フロー制御 {#flow-control}

-   スケジューラ フロー: 各 TiKV インスタンス上のスケジューラ トラフィックをリアルタイムで表示します。
-   スケジューラ破棄率: 各 TiKV インスタンスでのスケジューラ要求の拒否率。この比率が 0 より大きい場合、フロー制御が存在することを示します。1 `Compaction pending bytes`しきい値を超えると、TiKV は超過した部分に基づいて`Scheduler discard ratio`直線的に増加します。クライアントは拒否された要求を自動的に再試行します。
-   スロットル期間: L0 ファイルが多すぎるためにフロー制御がトリガーされたときに、スケジューラ要求の実行がブロックされた期間。このメトリックに値がある場合は、フロー制御が存在することを示します。
-   スケジューラ スロットル CF: フロー制御しきい値に達したときに RocksDB スロットルをトリガーする CF。
-   フロー コントローラー アクション: フロー制御しきい値に達したときに RocksDB スロットルをトリガーするアクション。
-   フラッシュ/L0 フロー: 各 TiKV インスタンス上の RocksDB の異なる CF のフラッシュと L0 圧縮のトラフィック。
-   フロー制御要因: RocksDB スロットルのトリガーに関連する要因。
-   圧縮保留バイト: 各 TiKV インスタンスでリアルタイムに圧縮を待機している RocksDB データのサイズ。
-   Txn コマンドのスロットル期間: スロットルによりトランザクションに関連するコマンドがブロックされた期間。通常、このメトリックは 0 です。
-   非トランザクション コマンドのスロットル期間: スロットルにより他のコマンドがブロックされた期間。通常、このメトリックは 0 です。

![TiKV Dashboard - Flow Control metrics](https://download.pingcap.com/images/docs/tikv-dashboard-flow-control.png)

### スケジューラ {#scheduler}

-   スケジューラ ステージ合計: 1 秒あたりの各ステージのコマンド数。短時間に多くのエラーが発生してはなりません。
-   スケジューラ書き込みバイト数: 各 TiKV インスタンスで処理されたコマンドによって書き込まれた合計バイト数
-   スケジューラ優先コマンド: 1 秒あたりの異なる優先コマンドの数
-   スケジューラ保留コマンド: TiKV インスタンスあたりの 1 秒あたりの保留コマンドの数

![TiKV Dashboard - Scheduler metrics](https://download.pingcap.com/images/docs/tikv-dashboard-scheduler.png)

### スケジューラ - コミット {#scheduler-commit}

-   スケジューラ ステージ合計: コミット コマンドを実行するときの、各ステージでの 1 秒あたりのコマンド数。短時間に多くのエラーが発生してはなりません。
-   スケジューラ コマンドの期間: コミット コマンドの実行にかかる時間。1 `1s`である必要があります。
-   スケジューラ ラッチ待機期間: コミット コマンドを実行するときにラッチによって発生する待機時間。 `1s`未満である必要があります。
-   スケジューラキー読み取り: コミットコマンドによって読み取られたキーの数
-   書き込まれたスケジューラキー: コミットコマンドによって書き込まれたキーの数
-   スケジューラ スキャンの詳細: キーは、コミット コマンドを実行するときに各 CF の詳細をスキャンします。
-   スケジューラスキャンの詳細 [ロック]: キーはコミットコマンドを実行するときにロックCFの詳細をスキャンします
-   スケジューラスキャンの詳細 [書き込み]: キーはコミットコマンドを実行するときに書き込みCFの詳細をスキャンします
-   スケジューラスキャンの詳細 [デフォルト]: キーはコミットコマンドを実行するときにデフォルトのCFの詳細をスキャンします

![TiKV Dashboard - Scheduler commit metrics](https://download.pingcap.com/images/docs/tikv-dashboard-scheduler-commit.png)

### スケジューラ - pessimistic_rollback {#scheduler-pessimistic-rollback}

-   スケジューラ ステージ合計: `pessimistic_rollback`コマンドを実行するときの、各ステージでの 1 秒あたりのコマンド数。短時間に多くのエラーが発生してはなりません。
-   スケジューラ コマンドの所要時間: `pessimistic_rollback`コマンドを実行するときに消費される時間。3 `1s`である必要があります。
-   スケジューラ ラッチ待機期間: `pessimistic_rollback`コマンドを実行するときにラッチによって発生する待機時間。3 `1s`である必要があります。
-   スケジューラキーの読み取り: `pessimistic_rollback`コマンドで読み取られたキーの数
-   書き込まれたスケジューラキー: `pessimistic_rollback`コマンドによって書き込まれたキーの数
-   スケジューラ スキャンの詳細: キーは、 `pessimistic_rollback`コマンドを実行するときに各 CF の詳細をスキャンします。
-   スケジューラスキャンの詳細 [ロック]: キーは、 `pessimistic_rollback`コマンドを実行するときにロックCFの詳細をスキャンします。
-   スケジューラスキャンの詳細 [書き込み]: キーは、 `pessimistic_rollback`コマンドを実行するときに書き込みCFの詳細をスキャンします。
-   スケジューラスキャンの詳細 [デフォルト]: キーは、 `pessimistic_rollback`コマンドを実行するときにデフォルトのCFの詳細をスキャンします。

### スケジューラ - 事前書き込み {#scheduler-prewrite}

-   スケジューラ ステージ合計: 事前書き込みコマンドを実行する際の、各ステージでの 1 秒あたりのコマンド数。短時間に大量のエラーが発生してはなりません。
-   スケジューラ コマンドの期間: 事前書き込みコマンドの実行にかかる時間。1 `1s`である必要があります。
-   スケジューラ ラッチ待機期間: プリライト コマンドを実行するときにラッチによって発生する待機時間。 `1s`未満である必要があります。
-   スケジューラキー読み取り: 事前書き込みコマンドによって読み取られたキーの数
-   書き込まれたスケジューラキー: 事前書き込みコマンドによって書き込まれたキーの数
-   スケジューラ スキャンの詳細: キーは、事前書き込みコマンドを実行するときに各 CF の詳細をスキャンします。
-   スケジューラスキャンの詳細 [ロック]: キーは、prewrite コマンドを実行するときにロック CF の詳細をスキャンします。
-   スケジューラスキャンの詳細 [書き込み]: キーは、書き込み前コマンドを実行するときに書き込み CF の詳細をスキャンします。
-   スケジューラスキャンの詳細 [デフォルト]: キーは、prewrite コマンドを実行するときにデフォルトの CF の詳細をスキャンします。

### スケジューラ - ロールバック {#scheduler-rollback}

-   スケジューラ ステージ合計: ロールバック コマンドを実行するときの、各ステージでの 1 秒あたりのコマンド数。短時間に多くのエラーが発生することはありません。
-   スケジューラ コマンドの期間: ロールバック コマンドの実行にかかる時間。1 `1s`である必要があります。
-   スケジューラ ラッチ待機期間: ロールバック コマンドを実行するときにラッチによって発生する待機時間。 `1s`未満である必要があります。
-   スケジューラキーの読み取り: ロールバックコマンドによって読み取られたキーの数
-   書き込まれたスケジューラキー: ロールバックコマンドによって書き込まれたキーの数
-   スケジューラ スキャンの詳細: キーは、ロールバック コマンドを実行するときに各 CF の詳細をスキャンします。
-   スケジューラスキャンの詳細 [ロック]: キーは、ロールバックコマンドを実行するときにロックCFの詳細をスキャンします。
-   スケジューラスキャンの詳細 [書き込み]: ロールバックコマンドを実行するときに、キーは書き込みCFの詳細をスキャンします。
-   スケジューラスキャンの詳細 [デフォルト]: キーは、ロールバックコマンドを実行するときにデフォルトのCFの詳細をスキャンします。

### GC {#gc}

-   GCタスク: gc_workerによって処理されたGCタスクの数
-   GCタスク期間: GCタスクの実行にかかる時間
-   TiDB GC秒数:GCの継続時間
-   TiDB GCワーカーアクション: TiDB GCワーカーアクションの数
-   ResolveLocks の進行状況: GC (Resolve Locks) の最初のフェーズの進行状況
-   TiKV Auto GCの進捗状況: GCの第2フェーズの進捗状況
-   GC 速度: 1 秒あたりに GC によって削除されるキーの数
-   TiKV自動GCセーフポイント: TiKV GCセーフポイントの値。セーフポイントは現在のGCタイムスタンプです。
-   GC の有効期間: TiDB GC の有効期間
-   GC間隔: TiDB GCの間隔
-   圧縮フィルター内の GC: 書き込み CF の圧縮フィルターでフィルターされたバージョンの数。

### スナップショット {#snapshot}

-   スナップショットメッセージのレート: Raftスナップショットメッセージが送信されるレート
-   99% スナップショット処理時間: スナップショットの処理にかかる時間 (P99)
-   スナップショット状態数: 状態ごとのスナップショットの数
-   99.99% スナップショットサイズ: スナップショットサイズ (P99.99)
-   99.99% スナップショット KV 数: スナップショット内の KV の数 (P99.99)

### タスク {#task}

-   ワーカーが処理したタスク: ワーカーが 1 秒あたりに処理したタスクの数
-   ワーカーの保留中のタスク: 1 秒あたりのワーカーの保留中および実行中のタスクの現在の数。通常は`1000`未満になります。
-   FuturePool が処理したタスク: Future Pool が 1 秒あたりに処理したタスクの数
-   FuturePool 保留タスク: 1 秒あたりの Future Pool の保留中および実行中のタスクの現在の数

### コプロセッサーの概要 {#coprocessor-overview}

-   リクエスト期間: コプロセッサリクエストを受信して​​からリクエストの処理が完了するまでの合計期間
-   合計リクエスト数: 1秒あたりのリクエスト数（種類別）
-   処理時間: 1分あたりにコプロセッサ要求を実際に処理するのに費やされた時間のヒストグラム
-   合計リクエスト エラー数:コプロセッサーの 1 秒あたりのリクエスト エラー数。短時間に大量のエラーが発生することはありません。
-   合計 KV カーソル操作数: `select` 、 `index` 、 `analyze_table` 、 `analyze_index` 、 `checksum_table` 、 `checksum_index`など、1 秒あたりのタイプ別の KV カーソル操作の合計数。
-   KV カーソル操作: 1 秒あたりの KV カーソル操作の種類別のヒストグラム
-   RocksDB パフォーマンス統計合計: RocksDB パフォーマンスの統計
-   合計応答サイズ: コプロセッサ応答の合計サイズ

### コプロセッサーの詳細 {#coprocessor-detail}

-   処理時間: 1分あたりにコプロセッサ要求を実際に処理するのに費やされた時間のヒストグラム
-   95% ストア別処理時間: TiKV インスタンスあたりのコプロセッサ要求の処理に 1 秒あたりに要した時間 (P95)
-   待機時間: コプロセッサ要求が処理されるのを待機している間の消費時間。1 (P99.99) `10s`である必要があります。
-   ストアごとの 95% 待機時間: コプロセッサ要求が処理されるのを待機している時間 (TiKV インスタンスあたり 1 秒あたり) (P95)
-   合計DAGリクエスト数: 1秒あたりのDAGリクエスト数の合計
-   DAGエグゼキューターの合計数: 1秒あたりのDAGエグゼキューターの合計数
-   合計操作の詳細（テーブルスキャン）：コプロセッサで選択スキャンを実行する際の1秒あたりのRocksDB内部操作の数
-   合計操作の詳細（インデックススキャン）：コプロセッサでインデックススキャンを実行するときの1秒あたりのRocksDB内部操作の数
-   CF別の合計操作詳細（テーブルスキャン）：コプロセッサで選択スキャンを実行する際の、1秒あたりの各CFのRocksDB内部操作の数
-   CF別の合計操作詳細（インデックススキャン）：コプロセッサでインデックススキャンを実行する際の、1秒あたりの各CFのRocksDB内部操作の数

### スレッド {#threads}

-   スレッドの状態: TiKV スレッドの状態
-   スレッドIO: 各TiKVスレッドのI/Oトラフィック
-   スレッドの自発的なコンテキストスイッチ: TiKV スレッドの自発的なコンテキストスイッチの数
-   スレッドの非自発的コンテキストスイッチ: TiKV スレッドの非自発的コンテキストスイッチの数

### RocksDB - kv/raft {#rocksdb-kv-raft}

-   取得操作: 1秒あたりの取得操作の数
-   取得時間: 取得操作の実行にかかる時間
-   シーク操作: 1秒あたりのシーク操作の回数
-   シーク時間: シーク操作を実行するときに消費される時間
-   書き込み操作: 1秒あたりの書き込み操作の数
-   書き込み時間: 書き込み操作の実行にかかる時間
-   WAL 同期操作: 1 秒あたりの WAL 同期操作の数
-   WAL書き込み時間: WALの書き込みにかかる時間
-   WAL同期時間: WAL同期操作の実行にかかる時間
-   圧縮操作: 1秒あたりの圧縮およびフラッシュ操作の数
-   圧縮時間: 圧縮とフラッシュ操作の実行にかかる時間
-   SST 読み取り時間: SST ファイルの読み取りにかかる時間
-   書き込みストール期間: 書き込みストール期間。通常は`0`になります。
-   メモリテーブルサイズ: 各カラムファミリーのメモリテーブルサイズ
-   Memtableヒット: memtableのヒット率
-   ブロック キャッシュ サイズ:ブロックキャッシュサイズ。共有ブロックキャッシュが無効になっている場合は、カラムファミリー別に分類されます。
-   ブロックキャッシュヒット:ブロックキャッシュのヒット率
-   ブロックキャッシュフロー:ブロックキャッシュ操作の種類ごとのフローレート
-   ブロックキャッシュ操作: タイプごとのブロックキャッシュ操作の数
-   キーフロー: キーの種類ごとの操作のフロー率
-   合計キー: 各カラムファミリーのキーの数
-   読み取りフロー: タイプごとの読み取り操作のフローレート
-   バイト / 読み取り: 読み取り操作あたりのバイト数
-   書き込みフロー: タイプごとの書き込み操作のフローレート
-   バイト / 書き込み: 書き込み操作あたりのバイト数
-   圧縮フロー: 圧縮操作の種類ごとのフロー速度
-   圧縮保留バイト数: 圧縮保留中のバイト数
-   読み取り増幅: TiKVインスタンスごとの読み取り増幅
-   圧縮率: 各レベルの圧縮率
-   スナップショットの数: TiKVインスタンスあたりのスナップショットの数
-   最も古いスナップショットの存続期間: 最も古い未リリースのスナップショットが存続する時間
-   各レベルのファイル数: 各レベルの異なる列ファミリの SST ファイルの数
-   SST取り込み時間 (秒): SST ファイルの取り込みに要した時間
-   各 CF の失速条件が変更されました: 各カラムファミリーの失速条件が変更されました

### Raft Engine {#raft-engine}

-   オペレーション
    -   書き込み: Raft Engineによる 1 秒あたりの書き込み操作の数
    -   read_entry: Raft Engineによる 1 秒あたりの raft ログ読み取り操作の数
    -   read_message: Raft Engineによる 1 秒あたりの Rafft メタデータ読み取り操作の数
-   書き込み時間: Raft Engineによる書き込み操作の時間。この時間は、これらのデータの書き込みに関係するディスク IO のレイテンシーの合計に近くなります。
-   流れ
    -   書き込み: Raft Engineの書き込みトラフィック
    -   書き換え追加: 書き換え追加ログのトラフィック
    -   書き換え書き換え: 書き換えのトラフィック書き換えログ
-   書き込み時間の内訳 (99%)
    -   wal: Raft Engine WAL の書き込みのレイテンシー
    -   wait: 書き込み前の待機時間
    -   適用: データをメモリに適用するのにかかる時間
-   バイト数/書き込み: Raft Engineが毎回書き込むバイト数
-   WAL 所要時間の内訳 (P99%): Raft EngineWAL の書き込みの各段階で消費された時間
-   ファイル数
    -   append: Raft Engineによってデータを追加するために使用するファイルの数
    -   rewrite: Raft Engineによるデータの書き換えに使用されるファイルの数 (rewrite は RocksDB の圧縮に似ています)
-   エントリー数
    -   rewrite: Raft Engineによって書き換えられたエントリの数
    -   append: Raft Engineによって追加されたエントリの数

### タイタン - すべて {#titan-all}

-   BLOBファイル数: Titan BLOBファイルの数
-   BLOBファイルサイズ: Titan BLOBファイルの合計サイズ
-   ライブ BLOB サイズ: 有効な BLOB レコードの合計サイズ
-   BLOBキャッシュヒット: Titanブロックキャッシュのヒット率
-   反復処理された BLOB ファイル数: 単一の反復処理に含まれる BLOB ファイルの数
-   BLOBファイルの破棄可能率分布: BLOBファイルのBLOBレコード失敗率分布
-   ブロブキーサイズ: Titanブロブキーのサイズ
-   ブロブ値のサイズ: Titanブロブ値のサイズ
-   BLOB 取得操作: Titan BLOB の取得操作の数
-   BLOB 取得時間: Titan BLOB で取得操作を実行するときに消費される時間
-   BLOB 反復操作: Titan BLOB で反復操作を実行するときに消費される時間
-   BLOBシーク時間: Titan BLOBでシーク操作を実行するときに消費される時間
-   BLOB の次の処理時間: Titan BLOB で次の操作を実行するときに消費される時間
-   BLOB 前の処理時間: Titan BLOB で前の処理を実行するときにかかる時間
-   ブロブキーフロー: Titanブロブキーの操作のフローレート
-   BLOBバイトフロー: Titan BLOBキーのバイトフローレート
-   BLOBファイルの読み取り時間: Titan BLOBファイルの読み取りにかかる時間
-   BLOBファイルの書き込み時間: Titan BLOBファイルの書き込みにかかる時間
-   BLOBファイル同期操作: BLOBファイル同期操作の数
-   BLOBファイル同期時間: BLOBファイルの同期にかかる時間
-   Blob GCアクション: Titan GCアクションの数
-   BLOB GC 期間: Titan GC 期間
-   BLOB GCキーフロー: Titan GCによって読み書きされるキーのフローレート
-   BLOB GCバイトフロー: Titan GCによって読み書きされるバイトのフローレート
-   BLOB GC入力ファイルサイズ: Titan GC入力ファイルのサイズ
-   BLOB GC出力ファイルサイズ: Titan GC出力ファイルのサイズ
-   BLOB GC ファイル数: Titan GC に関係する BLOB ファイルの数

### 悲観的ロック {#pessimistic-locking}

-   ロックマネージャスレッドCPU: ロックマネージャスレッドのCPU使用率
-   ロックマネージャが処理したタスク: ロックマネージャが処理したタスクの数
-   待機者の存続期間: ロックが解放されるまでのトランザクションの待機時間
-   待機テーブル: ロックの数やロックを待機しているトランザクションの数など、待機テーブルのステータス情報
-   デッドロック検出期間: デッドロックを検出するのにかかる時間
-   検出エラー: デッドロックの検出時に発生したエラーの数（デッドロックの数を含む）
-   デッドロック検出リーダー: デッドロック検出リーダーが配置されているノードの情報
-   合計悲観的ロックメモリサイズ: メモリ内の悲観的ロックが占有するメモリサイズ
-   メモリ内悲観的ロックの結果:悲観的ロックのみをメモリに保存した結果。1 `full` 、メモリ制限を超えたために悲観的ロックがメモリに保存されなかった回数を意味します。

### 解決済み-TS {#resolved-ts}

-   解決済みTSワーカーCPU:resolved-tsワーカースレッドのCPU使用率
-   Advance-TSワーカーCPU: Advance-TSワーカースレッドのCPU使用率
-   スキャンロックワーカーCPU: スキャンロックワーカースレッドのCPU使用率
-   resolved-tsの最大ギャップ: この TiKV 内のすべてのアクティブな領域のresolved-tsと現在の時刻との間の最大時間差
-   セーフ ts の最大ギャップ: この TiKV 内のすべてのアクティブ領域のセーフ ts と現在の時刻との間の最大時間差
-   最小解決TSリージョン:resolved-tsが最小であるリージョンのID
-   最小安全TSリージョン: 安全TSが最小であるリージョンのID
-   Leader期間の確認: リーダーリクエストの処理に費やされた時間の分布。期間は、リーダーでリクエストを送信してから応答を受信するまでです。
-   リージョンリーダーのresolved-tsの最大ギャップ: この TiKV 内のすべてのアクティブなリージョンのresolved-tsと現在の時刻との間の最大時間差 (リージョンリーダーのみ)
-   最小Leader解決TSリージョン:resolved-tsが最小であるリージョンのID（リージョンリーダーのみ）
-   ロックヒープサイズ: resolved-tsモジュール内のロックを追跡するヒープのサイズ

### メモリ {#memory}

-   アロケータ統計:メモリアロケータの統計

### バックアップ {#backup}

-   バックアップCPU: バックアップスレッドのCPU使用率
-   範囲サイズ: バックアップ範囲サイズのヒストグラム
-   バックアップ期間: バックアップにかかる時間
-   バックアップフロー: バックアップの合計バイト数
-   ディスクスループット: インスタンスあたりのディスクスループット
-   バックアップ範囲の所要時間: 範囲のバックアップにかかる時間
-   バックアップエラー: バックアップ中に発生したエラーの数

### 暗号化 {#encryption}

-   暗号化データキー: 暗号化されたデータキーの総数
-   暗号化されたファイル: 暗号化されたファイルの数
-   暗号化が初期化されました: 暗号化が有効かどうかを示します。1 `1`有効であることを意味します。
-   暗号化メタファイルのサイズ: 暗号化メタファイルのサイズ
-   データの暗号化/復号化ナノ秒: 毎回のデータの暗号化/復号化にかかる時間のヒストグラム
-   暗号化メタファイルの読み取り/書き込み時間: 暗号化メタファイルの読み取り/書き込みにかかる時間

### ログバックアップ {#log-backup}

-   処理イベントレート: 書き込みイベントの処理速度
-   初期スキャン生成イベントスループット: 新しいリスナーストリームを生成する際の増分スキャン速度
-   異常なチェックポイントTSラグ: 各タスクの現在のチェックポイントTSから現在までのラグ
-   イベントのメモリ: 増分スキャンによって生成された一時データによって占有されるメモリの推定量
-   観測されたリージョン数: 現在聴取されているリージョンの数
-   エラー: 再試行可能なエラーと致命的ではないエラーの数と種類
-   致命的なエラー: 致命的なエラーの数と種類。通常、致命的なエラーが発生すると、タスクが一時停止します。
-   タスクのチェックポイント TS: 各タスクのチェックポイント TS
-   フラッシュ期間: キャッシュされたデータを外部storageに移動するのにかかる時間のヒートマップ
-   初期スキャン期間: 新しいリスニングストリームを作成するときに増分スキャンにかかる時間のヒートマップ
-   Raftイベント期間の変換: リスニング ストリームを作成した後、 Raftログ エントリをバックアップ データに変換するのにかかる時間のヒート マップ
-   コマンドバッチサイズ: リスニングRaftコマンドのバッチサイズ（単一のRaftグループ内）
-   一時ファイルへの保存時間: 複数のタスクにまたがるバックアップ データのバッチを一時ファイル領域に一時的に保存するのにかかる時間のヒート マップ
-   一時ファイルへの書き込み時間: バックアップ データのバッチ (特定のタスクから) を一時ファイル領域に一時的に保存するのにかかる時間のヒート マップ
-   システム書き込み呼び出し時間: バックアップ データのバッチ (リージョンから) を一時ファイルに書き込むのにかかる時間のヒート マップ
-   内部メッセージタイプ: TiKV内でログバックアップを担当するアクターが受信したメッセージのタイプ
-   内部メッセージ処理時間（P90|P99）：各タイプのメッセージの消費と処理の速度
-   初期スキャン RocksDB スループット: 増分スキャン中に RocksDB 内部ログによって生成される読み取りトラフィック
-   初期スキャン RocksDB 操作: 増分スキャン中に RocksDB によって内部的に記録された個々の操作の数
-   初期スキャンのトリガー理由: 増分スキャンをトリガーする理由
-   リージョンチェックポイント キーの配置: PD に記録されたチェックポイント操作の数

> **注記：**
>
> 以下の監視メトリックはすべて TiDB ノードをデータ ソースとして使用しますが、ログ バックアップ プロセスに何らかの影響を及ぼします。そのため、参照しやすいように**TiKV 詳細**ダッシュボードに配置されています。ほとんどの場合、TiKV は積極的に進行をプッシュしますが、以下の監視メトリックの一部にサンプリングされたデータがないことがあるのは正常です。

-   チェックポイントバッチサイズ要求: ログバックアップコーディネータが各TiKVのチェックポイント情報を要求するときの要求バッチサイズ
-   ティック期間 [P99|P90]: コーディネータ内のティックにかかる時間
-   リージョンチェックポイントの失敗理由:リージョンチェックポイントがコーディネータ内で進めない理由
-   リクエスト結果: コーディネータがリージョンチェックポイントを進めることに成功したか失敗したかの記録
-   リージョン取得操作回数: コーディネータがPDからリージョン情報を要求した回数
-   前進トリガ時間: コーディネータがチェックポイントの前進を試行するのにかかる時間

### 共通パラメータの説明 {#explanation-of-common-parameters}

#### gRPC メッセージタイプ {#grpc-message-type}

1.  トランザクション API:

    -   kv_get: `ts`で指定されたデータの最新バージョンを取得するコマンド
    -   kv_scan: データの範囲をスキャンするコマンド
    -   kv_prewrite: 2PC の最初のフェーズでコミットするデータを事前に書き込むコマンド
    -   kv_pessimistic_lock: 他のトランザクションがこのキーを変更できないようにするためにキーに悲観的ロックを追加するコマンド
    -   kv_pessimistic_rollback: キーの悲観的ロックを削除するコマンド
    -   kv_txn_heart_beat:悲観的トランザクションや大規模なトランザクションがロールバックされないように、 `lock_ttl`更新するコマンド
    -   kv_check_txn_status: トランザクションのステータスを確認するコマンド
    -   kv_commit: 事前書き込みコマンドによって書き込まれたデータをコミットするコマンド
    -   kv_cleanup: トランザクションをロールバックするコマンド。v4.0 では非推奨です。
    -   kv_batch_get: `kv_get`と同様に、バッチキーの値を一度に取得するコマンド
    -   kv_batch_rollback: 複数の事前書き込みトランザクションのバッチロールバックのコマンド
    -   kv_scan_lock: 期限切れのトランザクションをクリーンアップするために、バージョン番号が`max_version`より前のすべてのロックをスキャンするコマンド
    -   kv_resolve_lock: トランザクションの状態に応じて、トランザクション ロックをコミットまたはロールバックするコマンド。
    -   kv_gc: GCのコマンド
    -   kv_delete_range: TiKVからデータの範囲を削除するコマンド

2.  生のAPI:

    -   raw_get: キーの値を取得するコマンド
    -   raw_batch_get: バッチキーの値を取得するコマンド
    -   raw_scan: データの範囲をスキャンするコマンド
    -   raw_batch_scan: 連続する複数のデータ範囲をスキャンするコマンド
    -   raw_put: キー/値のペアを書き込むコマンド
    -   raw_batch_put: キーと値のペアを一括して書き込むコマンド
    -   raw_delete: キー/値のペアを削除するコマンド
    -   raw_batch_delete: キー/値のペアのバッチコマンド
    -   raw_delete_range: データの範囲を削除するコマンド

## TiKV-FastTuneダッシュボード {#tikv-fasttune-dashboard}

QPS ジッター、レイテンシージッター、レイテンシー増加傾向などの TiKV のパフォーマンス問題が発生した場合、 **TiKV-FastTune**ダッシュボードを確認できます。このダッシュボードには、特にクラスター内の書き込みワークロードが中規模または大規模の場合に診断に役立つ一連のパネルが含まれています。

書き込み関連のパフォーマンスの問題が発生した場合は、まず TiDB 関連のダッシュボードを確認します。問題がstorage側にある場合は、 **TiKV-FastTune**ページを開き、その上のすべてのパネルを参照して確認します。

**TiKV-FastTune**ダッシュボードには、パフォーマンスの問題の考えられる原因を示すタイトルが表示されます。提案された原因が正しいかどうかを確認するには、ページ上のグラフを確認します。

グラフの左側の Y 軸はstorage側の書き込み RPC QPS を表し、右側の Y 軸のグラフのセットは上下逆さまに描画されます。左側のグラフの形状が右側のグラフの形状と一致する場合、提案された原因は正しいです。

詳細な指標と説明については、ダッシュボード[ユーザーマニュアル](https://docs.google.com/presentation/d/1aeBF2VCKf7eo4-3TMyP7oPzFWIih6UBA53UI8YQASCQ/edit#slide=id.gab6b984c2a_1_352)を参照してください。
