---
title: Glossary
summary: TiDB に関する用語集。
---

# 用語集 {#glossary}

## あ {#a}

### ACID {#acid}

ACID は、トランザクションの 4 つの主要な特性、つまり原子性、一貫性、独立性、および永続性を指します。これらの各特性については、以下で説明します。

-   **アトミック性とは**、操作のすべての変更が実行されるか、まったく実行されないかのいずれかを意味します。TiDB は、トランザクションのアトミック性を実現するために、主キーを格納する[リージョン](#regionpeerraft-group)のアトミック性を保証します。

-   **一貫性とは**、トランザクションが常にデータベースをある一貫性のある状態から別の一貫性のある状態に移行することを意味します。TiDB では、データをメモリに書き込む前にデータの一貫性が確保されます。

-   **分離とは**、進行中のトランザクションが完了するまで他のトランザクションから見えないことを意味します。これにより、同時トランザクションは一貫性を犠牲にすることなくデータの読み取りと書き込みを行うことができます。TiDB は現在、分離レベル`REPEATABLE READ`をサポートしています。

-   **耐久性とは**、トランザクションが一度コミットされると、システム障害が発生した場合でもコミットされたままになることを意味します。TiKV は永続storageを使用して耐久性を確保します。

## B {#b}

### バッチテーブル作成 {#batch-create-table}

バッチテーブル作成は、TiDB v6.0.0 で導入された機能です。この機能はデフォルトで有効になっていますBR (バックアップと復元) を使用して多数のテーブル (約 50000) を含むデータを復元する場合、この機能を使用すると、バッチでテーブルを作成することで復元プロセスを大幅に高速化できます。詳細については、 [バッチテーブル作成](/br/br-batch-create-table.md)参照してください。

### ベースラインキャプチャ {#baseline-capturing}

ベースライン キャプチャは、キャプチャ条件を満たすクエリをキャプチャし、それらのバインディングを作成します。これは[アップグレード中の実行計画の回帰を防ぐ](/sql-plan-management.md#prevent-regression-of-execution-plans-during-an-upgrade)に使用されます。

### バケツ {#bucket}

[リージョン](#regionpeerraft-group)論理的にバケットと呼ばれるいくつかの小さな範囲に分割されます。TiKV はバケットごとにクエリ統計を収集し、バケットのステータスを PD に報告します。詳細については、 [バケット設計ドキュメント](https://github.com/tikv/rfcs/blob/master/text/0082-dynamic-size-region.md#bucket)を参照してください。

## Ｃ {#c}

### キャッシュされたテーブル {#cached-table}

キャッシュテーブル機能を使用すると、TiDB はテーブル全体のデータを TiDBサーバーのメモリにロードし、TiKV にアクセスせずにメモリからテーブルデータを直接取得するため、読み取りパフォーマンスが向上します。

### パーティションの結合 {#coalesce-partition}

パーティション結合は、ハッシュまたはキーでパーティションテーブル内のパーティションの数を減らす方法です。詳細については、 [ハッシュとキーのパーティションを管理する](/partitioned-table.md#manage-hash-and-key-partitions)を参照してください。

### 継続的なプロファイリング {#continuous-profiling}

TiDB 5.3.0 で導入された継続的プロファイリングは、システム コール レベルでリソース オーバーヘッドを観察する方法です。継続的プロファイリングのサポートにより、TiDB はデータベース ソース コードを直接調べるのと同じくらい明確なパフォーマンス情報を提供し、R&amp;D および運用保守担当者がフレーム グラフを使用してパフォーマンスの問題の根本原因を特定するのに役立ちます。詳細については、 [TiDB ダッシュボード インスタンス プロファイリング - 継続的なプロファイリング](/dashboard/continuous-profiling.md)参照してください。

## だ {#d}

### 動的剪定 {#dynamic-pruning}

動的プルーニングモードは、TiDB がパーティション テーブルにアクセスするモードの 1 つです。動的プルーニング モードでは、各演算子は複数のパーティションへの直接アクセスをサポートします。そのため、TiDB は Union を使用しなくなりました。Union 操作を省略すると、実行効率が向上し、Union の同時実行の問題を回避できます。

## 私 {#i}

### インデックスの結合 {#index-merge}

インデックス マージは、TiDB v4.0 で導入されたテーブルへのアクセス方法です。この方法を使用すると、TiDB オプティマイザーはテーブルごとに複数のインデックスを使用し、各インデックスによって返された結果をマージできます。シナリオによっては、この方法によりテーブル全体のスキャンが回避され、クエリの効率が向上します。v5.4 以降、インデックス マージは GA 機能になりました。

### インメモリ悲観的ロック {#in-memory-pessimistic-lock}

インメモリ悲観的ロックは、TiDB v6.0.0 で導入された新機能です。この機能を有効にすると、悲観的ロックは通常、リージョンリーダーのメモリにのみ保存され、ディスクに永続化されず、 Raftを介して他のレプリカに複製されません。この機能により、悲観的ロックの取得にかかるオーバーヘッドが大幅に削減され、悲観的トランザクションのスループットが向上します。

## ら {#l}

### リーダー/フォロワー/学習者 {#leader-follower-learner}

Leader/Follower/Learnerはそれぞれ、 [仲間](#regionpeerraft-group)のRaftグループ内の役割に対応します。リーダーはすべてのクライアント要求に応え、フォロワーにデータを複製します。グループ リーダーが失敗した場合、フォロワーの 1 人が新しいリーダーとして選出されます。学習者は、レプリカの追加プロセスでのみ機能する、投票権のないフォロワーです。

## ま {#m}

### マルチレベル {#mpp}

v5.0 以降、TiDB はTiFlashノードを介して大規模並列処理 (MPP)アーキテクチャを導入し、大規模な結合クエリの実行ワークロードをTiFlashノード間で共有します。MPP モードを有効にすると、TiDB はコストに基づいて、MPP フレームワークを使用して計算を実行するかどうかを決定します。MPP モードでは、計算中に結合キーが Exchange 操作を通じて再分配されるため、計算負荷が各TiFlashノードに分散され、計算が高速化されます。詳細については、 [TiFlash MPPモードを使用する](/tiflash/use-tiflash-mpp-mode.md)参照してください。

### マルチバージョン同時実行制御 (MVCC) {#multi-version-concurrency-control-mvcc}

[MVCC](https://en.wikipedia.org/wiki/Multiversion_concurrency_control)は、TiDB やその他のデータベースにおける同時実行制御メカニズムです。トランザクションによって読み取られたメモリを処理して、TiDB への同時アクセスを実現し、同時読み取りと書き込みの競合によるブロッキングを回避します。

## お {#o}

### 古い値 {#old-value}

TiCDC が出力する増分変更ログ内の「元の値」。TiCDC が出力する増分変更ログに「元の値」を含めるかどうかを指定できます。

### オペレーター {#operator}

オペレーターは、スケジュール設定の目的でリージョンに適用されるアクションの集合です。オペレーターは、「リージョン2 のリーダーをストア 5 に移行する」や「リージョン2 のレプリカをストア 1、4、5 に移行する」などのスケジュール設定タスクを実行します。

演算子は[スケジューラ](#scheduler)によって計算および生成することも、外部 API によって作成することもできます。

### オペレータステップ {#operator-step}

オペレータ ステップは、オペレータの実行におけるステップです。オペレータには通常、複数のオペレータ ステップが含まれます。

現在、PD によって生成される利用可能なステップは次のとおりです。

-   `TransferLeader` : 指定されたメンバーにリーダーシップを移譲する
-   `AddPeer` : 指定されたストアにピアを追加します
-   `RemovePeer` :リージョンのピアを削除します
-   `AddLearner` : 指定されたストアに学習者を追加する
-   `PromoteLearner` : 指定された学習者を投票メンバーに昇格させる
-   `SplitRegion` : 指定されたリージョンを2つに分割します

## ポ {#p}

### パーティショニング {#partitioning}

[パーティショニング](/partitioned-table.md) 、テーブルを物理的に小さなテーブル パーティションに分割することを指します。これは、RANGE、LIST、HASH、KEY パーティション分割などのパーティション メソッドによって実行できます。

### 保留中/ダウン {#pending-down}

「保留中」と「ダウン」は、ピアの 2 つの特別な状態です。保留中は、フォロワーまたは学習者のRaftログがリーダーのログと大きく異なることを示します。保留中のフォロワーはリーダーとして選出できません。「ダウン」は、ピアがリーダーに長時間応答しなくなった状態を指し、通常は対応するノードがダウンしているか、ネットワークから分離されていることを意味します。

### ポイントゲット {#point-get}

ポイント取得とは、一意のインデックスまたはプライマリ インデックスによって 1 行のデータを読み取ることを意味し、返される結果セットは最大 1 行になります。

### 述語列 {#predicate-columns}

ほとんどの場合、SQL 文を実行するときに、オプティマイザは一部の列 ( `WHERE` 、 `JOIN` 、 `ORDER BY` 、および`GROUP BY`文の列など) の統計情報のみを使用します。これらの使用される列は述語列と呼ばれます。詳細については、 [いくつかの列の統計を収集する](/statistics.md#collect-statistics-on-some-columns)を参照してください。

## 質問 {#q}

### クォータリミッター {#quota-limiter}

クォータ リミッターは、TiDB v6.0.0 で導入された実験的機能です。TiKV がデプロイされているマシンのリソースが限られている場合 (たとえば、4v CPU と 16 Gメモリのみ)、TiKV のフォアグラウンドが読み取りおよび書き込み要求を過度に処理すると、バックグラウンドで使用される CPU リソースがそのような要求の処理に占有され、TiKV のパフォーマンスの安定性に影響します。この状況を回避するには、 [クォータ関連の設定項目](/tikv-configuration-file.md#quota)設定して、フォアグラウンドで使用される CPU リソースを制限できます。

## R {#r}

### Raft Engine {#raft-engine}

Raft Engineは、ログ構造設計の組み込み永続storageエンジンです。TiKV が複数の Raft ログを保存できるように構築されています。v5.4 以降、TiDB はログstorageエンジンとしてRaft Engineの使用をサポートしています。詳細については、 [Raft Engine](/tikv-configuration-file.md#raft-engine)参照してください。

### リージョン/ ピア /Raftグループ {#region-peer-raft-group}

リージョンはTiKV のデータstorageの最小部分であり、それぞれがデータの範囲 (デフォルトでは 96 MiB) を表します。各リージョンには、デフォルトで 3 つのレプリカがあります。リージョンのレプリカはピアと呼ばれます。同じリージョンの複数のピアは、 Raftコンセンサス アルゴリズムを介してデータを複製するため、ピアもRaftインスタンスのメンバーになります。TiKV は、Multi-Raft を使用してデータを管理します。つまり、各リージョンには、対応する分離されたRaftグループが存在します。

### リージョン分割 {#region-split}

データの書き込みが増加すると、領域が生成されます。分割のプロセスは、リージョン分割と呼ばれます。

リージョン分割のメカニズムは、1 つの初期リージョンを使用してキー空間全体をカバーし、リージョンのサイズまたはキーの数がしきい値に達するたびに既存の領域を分割して新しい領域を生成することです。

### 復元する {#restore}

復元はバックアップ操作の逆です。準備されたバックアップからデータを取得して、システムを以前の状態に戻すプロセスです。

## S {#s}

### スケジューラ {#scheduler}

スケジューラは、PD 内のスケジュール タスクを生成するコンポーネントです。PD 内の各スケジューラは独立して実行され、異なる目的を果たします。よく使用されるスケジューラは次のとおりです。

-   `balance-leader-scheduler` : リーダーの分布を均等にする
-   `balance-region-scheduler` : ピアの分散をバランスさせる
-   `hot-region-scheduler` : ホット領域の分布をバランスさせる
-   `evict-leader-{store-id}` : ノードのすべてのリーダーを排除します (ローリング アップグレードでよく使用されます)

### 店 {#store}

ストアとは、TiKV クラスター内のstorageノード ( `tikv-server`のインスタンス) を指します。各ストアには対応する TiKV インスタンスがあります。

## T {#t}

### Top SQL {#top-sql}

Top SQL は、指定された時間範囲内で TiDB または TiKV ノードの高負荷の原因となっている SQL クエリを見つけるのに役立ちます。詳細については、 [Top SQLユーザードキュメント](/dashboard/top-sql.md)を参照してください。

### TSO {#tso}

TiKV は分散storageシステムであるため、単調に増加するタイムスタンプを割り当てるには、グローバル タイミング サービスである Timestamp Oracle (TSO) が必要です。TiKV では、このような機能は PD によって提供され、Google [スパナ](http://static.googleusercontent.com/media/research.google.com/en//archive/spanner-osdi2012.pdf)では、この機能は複数のアトミック時計と GPS によって提供されます。

### 10 ... {#ttl}

[存続時間 (TTL)](/time-to-live.md) 、TiDB データの有効期間を行レベルで管理できる機能です。TTL 属性を持つテーブルの場合、TiDB は自動的にデータの有効期間をチェックし、期限切れのデータを行レベルで削除します。
